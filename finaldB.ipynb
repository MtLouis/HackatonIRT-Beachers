{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon\n",
    "\n",
    "Some utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 - DL tutorial - 1st CNN.ipynb  fileCountLabels.pickle  \u001b[0m\u001b[01;34mhackathon\u001b[0m/\r\n",
      "Db_proportions.h5                finaldB.ipynb           pickle.pickle\r\n",
      "\u001b[01;34mdata\u001b[0m/                            fulltoFFT.ipynb         test.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
      "\u001b[K    100% |################################| 337kB 3.3MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading PyYAML-3.12.tar.gz (253kB)\n",
      "\u001b[K    100% |################################| 256kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2c/f7/79/13f3a12cd723892437c0cfbde1230ab4d82947ff7b3839a4fc\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.1.5 pyyaml-3.12\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "PATH_DATA = 'data/full.h5'\n",
    "PATH_PREDICT_WITHOUT_GT = 'data/pred_eighties_from_full_1_without_gt.h5'\n",
    "#PATH_SUBMIT = 'data/submit/pred_eighties_from_half_1_AWESOMEGROUP.h5'\n",
    "#PATH_PREDICT_WITH_GT = 'data/pred_teachers/pred_eighties_from_half_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout\n",
    "import keras.layers.normalization \n",
    "from keras.callbacks import Callback\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5.File(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 18698240)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(f['S2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs(h5_path):\n",
    "    f = h5.File(h5_path)\n",
    "    return range(len(f['S2']))\n",
    "\n",
    "def shuffle_idx(sample_idxs):\n",
    "    return list(np.random.permutation(sample_idxs))\n",
    "\n",
    "def split_train_val(sample_idxs, proportion):\n",
    "    n_samples = len(sample_idxs)\n",
    "    return sample_idxs[:int((1.-proportion)*n_samples)], sample_idxs[int((1.-proportion)*n_samples):]\n",
    "\n",
    "def get_batch_count(idxs, batch_size):\n",
    "    batch_count = int(len(idxs)//batch_size)\n",
    "    remained_samples = len(idxs)%batch_size\n",
    "    if remained_samples > 0:\n",
    "        batch_count += 1\n",
    "\n",
    "    return batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = f['S2'][batch_idxs, :,:,:]\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = get_idxs(PATH_DATA)\n",
    "shuffled_idxs = shuffle_idx(idxs)\n",
    "train_idxs, val_idxs = split_train_val(shuffled_idxs, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen = generator(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6bd83b136895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TOP_LANDCOVER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcountLabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TOP_LANDCOVER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "countLabels = np.zeros([23,2])\n",
    "\n",
    "for i in range(22):\n",
    "    countLabels[i+1][0] = countLabels[i][0] + 1\n",
    "\n",
    "for i in range(len(f['TOP_LANDCOVER'])):\n",
    "    countLabels[int(f['TOP_LANDCOVER'][i])][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# print(\"countLabels saved\")\n",
    "# fileLabels = open('fileCountLabels.pickle', 'wb')\n",
    "# pickle.dump(countLabels, fileLabels)\n",
    "# fileLabels.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 3.827110e+06],\n",
       "       [2.000000e+00, 1.250253e+06],\n",
       "       [3.000000e+00, 2.315736e+06],\n",
       "       [4.000000e+00, 7.769660e+05],\n",
       "       [5.000000e+00, 2.167443e+06],\n",
       "       [6.000000e+00, 6.330000e+02],\n",
       "       [7.000000e+00, 0.000000e+00],\n",
       "       [8.000000e+00, 0.000000e+00],\n",
       "       [9.000000e+00, 3.709000e+03],\n",
       "       [1.000000e+01, 1.112499e+06],\n",
       "       [1.100000e+01, 7.657050e+05],\n",
       "       [1.200000e+01, 4.054392e+06],\n",
       "       [1.300000e+01, 1.281000e+03],\n",
       "       [1.400000e+01, 6.341420e+05],\n",
       "       [1.500000e+01, 3.847000e+03],\n",
       "       [1.600000e+01, 0.000000e+00],\n",
       "       [1.700000e+01, 8.647100e+04],\n",
       "       [1.800000e+01, 3.829000e+03],\n",
       "       [1.900000e+01, 1.154414e+06],\n",
       "       [2.000000e+01, 5.382200e+05],\n",
       "       [2.100000e+01, 1.590000e+03],\n",
       "       [2.200000e+01, 0.000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from file\n",
    "import pickle\n",
    "fileLabels = open('pickle.pickle', 'rb')\n",
    "countLabels = pickle.load(fileLabels)  # variables come out in the order you put them in\n",
    "fileLabels.close()\n",
    "countLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = np.sum(countLabels[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.04677553e+01],\n",
       "       [2.00000000e+00, 6.68647424e+00],\n",
       "       [3.00000000e+00, 1.23847806e+01],\n",
       "       [4.00000000e+00, 4.15528948e+00],\n",
       "       [5.00000000e+00, 1.15916953e+01],\n",
       "       [6.00000000e+00, 3.38534536e-03],\n",
       "       [7.00000000e+00, 0.00000000e+00],\n",
       "       [8.00000000e+00, 0.00000000e+00],\n",
       "       [9.00000000e+00, 1.98360915e-02],\n",
       "       [1.00000000e+01, 5.94975249e+00],\n",
       "       [1.10000000e+01, 4.09506456e+00],\n",
       "       [1.20000000e+01, 2.16832814e+01],\n",
       "       [1.30000000e+01, 6.85091217e-03],\n",
       "       [1.40000000e+01, 3.39145289e+00],\n",
       "       [1.50000000e+01, 2.05741289e-02],\n",
       "       [1.60000000e+01, 0.00000000e+00],\n",
       "       [1.70000000e+01, 4.62455290e-01],\n",
       "       [1.80000000e+01, 2.04778632e-02],\n",
       "       [1.90000000e+01, 6.17391797e+00],\n",
       "       [2.00000000e+01, 2.87845273e+00],\n",
       "       [2.10000000e+01, 8.50347412e-03],\n",
       "       [2.20000000e+01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countlbl = np.zeros([23,2])\n",
    "for i in range(22):\n",
    "    countlbl[i+1][0] = countlbl[i][0] + 1\n",
    "    \n",
    "countlbl[:,1] = 100 * countLabels[:,1]/tot #np.around(100 * countLabels[:,1]/tot, decimals = 3)\n",
    "\n",
    "countlbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 1,  2],\n",
       "       [ 2,  3],\n",
       "       [ 3,  4],\n",
       "       [ 4,  5],\n",
       "       [ 5, 10],\n",
       "       [ 6, 11],\n",
       "       [ 7, 12],\n",
       "       [ 8, 14],\n",
       "       [ 9, 17],\n",
       "       [10, 19],\n",
       "       [11, 20]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tailleDB = 700000\n",
    "DB = np.zeros([tailleDB, 16, 16, 4, 1])\n",
    "\n",
    "# Correspondance : chaque élément est de type [i,j] où j est la classe originale reliée désormais à l'indice i \n",
    "cor = np.zeros([12,2], dtype=int)\n",
    "for i in range(11):\n",
    "    cor[i+1][0] = cor[i][0] + 1\n",
    "\n",
    "tempLab = 0\n",
    "for i in range(23):\n",
    "    if countlbl[i,1] > 0.2:\n",
    "        cor[tempLab][1] = i\n",
    "        tempLab += 1\n",
    "\n",
    "lblAdded = np.zeros([23,2], dtype = int)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(f['TOP_LANDCOVER'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699438"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lblComplete = np.zeros([23,2], dtype=int)\n",
    "for i in range(22):\n",
    "    lblComplete[i+1][0] = lblComplete[i][0] + 1\n",
    "\n",
    "for i in range(22):\n",
    "    if i in cor[:,1]:\n",
    "        lblComplete[i,1] = countlbl[i,1]/100 * tailleDB\n",
    "    else:\n",
    "        lblComplete[i,1] = 0\n",
    "    \n",
    "lblComplete\n",
    "np.sum(lblComplete[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff018848470>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff018886550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f['TOP_LANDCOVER'][:2000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBatch = f['S2'][10:10010]\n",
    "dataClass = f['TOP_LANDCOVER'][10:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n",
      "291000\n",
      "292000\n",
      "293000\n",
      "294000\n",
      "295000\n",
      "296000\n",
      "297000\n",
      "298000\n",
      "299000\n",
      "300000\n",
      "301000\n",
      "302000\n",
      "303000\n",
      "304000\n",
      "305000\n",
      "306000\n",
      "307000\n",
      "308000\n",
      "309000\n",
      "310000\n",
      "311000\n",
      "312000\n",
      "313000\n",
      "314000\n",
      "315000\n",
      "316000\n",
      "317000\n",
      "318000\n",
      "319000\n",
      "320000\n",
      "321000\n",
      "322000\n",
      "323000\n",
      "324000\n",
      "325000\n",
      "326000\n",
      "327000\n",
      "328000\n",
      "329000\n",
      "330000\n",
      "331000\n",
      "332000\n",
      "333000\n",
      "334000\n",
      "335000\n",
      "336000\n",
      "337000\n",
      "338000\n",
      "339000\n",
      "340000\n",
      "341000\n",
      "342000\n",
      "343000\n",
      "344000\n",
      "345000\n",
      "346000\n",
      "347000\n",
      "348000\n",
      "349000\n",
      "350000\n",
      "351000\n",
      "352000\n",
      "353000\n",
      "354000\n",
      "355000\n",
      "356000\n",
      "357000\n",
      "358000\n",
      "359000\n",
      "360000\n",
      "361000\n",
      "362000\n",
      "363000\n",
      "364000\n",
      "365000\n",
      "366000\n",
      "367000\n",
      "368000\n",
      "369000\n",
      "370000\n",
      "371000\n",
      "372000\n",
      "373000\n",
      "374000\n",
      "375000\n",
      "376000\n",
      "377000\n",
      "378000\n",
      "379000\n",
      "380000\n",
      "381000\n",
      "382000\n",
      "383000\n",
      "384000\n",
      "385000\n",
      "386000\n",
      "387000\n",
      "388000\n",
      "389000\n",
      "390000\n",
      "391000\n",
      "392000\n",
      "393000\n",
      "394000\n",
      "395000\n",
      "396000\n",
      "397000\n",
      "398000\n",
      "399000\n",
      "400000\n",
      "401000\n",
      "402000\n",
      "403000\n",
      "404000\n",
      "405000\n",
      "406000\n",
      "407000\n",
      "408000\n",
      "409000\n",
      "410000\n",
      "411000\n",
      "412000\n",
      "413000\n",
      "414000\n",
      "415000\n",
      "416000\n",
      "417000\n",
      "418000\n",
      "419000\n",
      "420000\n",
      "421000\n",
      "422000\n",
      "423000\n",
      "424000\n",
      "425000\n",
      "426000\n",
      "427000\n",
      "428000\n",
      "429000\n",
      "430000\n",
      "431000\n",
      "432000\n",
      "433000\n",
      "434000\n",
      "435000\n",
      "436000\n",
      "437000\n",
      "438000\n",
      "439000\n",
      "440000\n",
      "441000\n",
      "442000\n",
      "443000\n",
      "444000\n",
      "445000\n",
      "446000\n",
      "447000\n",
      "448000\n",
      "449000\n",
      "450000\n",
      "451000\n",
      "452000\n",
      "453000\n",
      "454000\n",
      "455000\n",
      "456000\n",
      "457000\n",
      "458000\n",
      "459000\n",
      "460000\n",
      "461000\n",
      "462000\n",
      "463000\n",
      "464000\n",
      "465000\n",
      "466000\n",
      "467000\n",
      "468000\n",
      "469000\n",
      "470000\n",
      "471000\n",
      "472000\n",
      "473000\n",
      "474000\n",
      "475000\n",
      "476000\n",
      "477000\n",
      "478000\n",
      "479000\n",
      "480000\n",
      "481000\n",
      "482000\n",
      "483000\n",
      "484000\n",
      "485000\n",
      "486000\n",
      "487000\n",
      "488000\n",
      "489000\n",
      "490000\n",
      "491000\n",
      "492000\n",
      "493000\n",
      "494000\n",
      "495000\n",
      "496000\n",
      "497000\n",
      "498000\n",
      "499000\n",
      "500000\n",
      "501000\n",
      "502000\n",
      "503000\n",
      "504000\n",
      "505000\n",
      "506000\n",
      "507000\n",
      "508000\n",
      "509000\n",
      "510000\n",
      "511000\n",
      "512000\n",
      "513000\n",
      "514000\n",
      "515000\n",
      "516000\n",
      "517000\n",
      "518000\n",
      "519000\n",
      "520000\n",
      "521000\n",
      "522000\n",
      "523000\n",
      "524000\n",
      "525000\n",
      "526000\n",
      "527000\n",
      "528000\n",
      "529000\n",
      "530000\n",
      "531000\n",
      "532000\n",
      "533000\n",
      "534000\n",
      "535000\n",
      "536000\n",
      "537000\n",
      "538000\n",
      "539000\n",
      "540000\n",
      "541000\n",
      "542000\n",
      "543000\n",
      "544000\n",
      "545000\n",
      "546000\n",
      "547000\n",
      "548000\n",
      "549000\n",
      "550000\n",
      "551000\n",
      "552000\n",
      "553000\n",
      "554000\n",
      "555000\n",
      "556000\n",
      "557000\n",
      "558000\n",
      "559000\n",
      "560000\n",
      "561000\n",
      "562000\n",
      "563000\n",
      "564000\n",
      "565000\n",
      "566000\n",
      "567000\n",
      "568000\n",
      "569000\n",
      "570000\n",
      "571000\n",
      "572000\n",
      "573000\n",
      "574000\n",
      "575000\n",
      "576000\n",
      "577000\n",
      "578000\n",
      "579000\n",
      "580000\n",
      "581000\n",
      "582000\n",
      "583000\n",
      "584000\n",
      "585000\n",
      "586000\n",
      "587000\n",
      "588000\n",
      "589000\n",
      "590000\n",
      "591000\n",
      "592000\n",
      "593000\n",
      "594000\n",
      "595000\n",
      "596000\n",
      "597000\n",
      "598000\n",
      "599000\n",
      "600000\n",
      "601000\n",
      "602000\n",
      "603000\n",
      "604000\n",
      "605000\n",
      "606000\n",
      "607000\n",
      "608000\n",
      "609000\n",
      "610000\n",
      "611000\n",
      "612000\n",
      "613000\n",
      "614000\n",
      "615000\n",
      "616000\n",
      "617000\n",
      "618000\n",
      "619000\n",
      "620000\n",
      "621000\n",
      "622000\n",
      "623000\n",
      "624000\n",
      "625000\n",
      "626000\n",
      "627000\n",
      "628000\n",
      "629000\n",
      "630000\n",
      "631000\n",
      "632000\n",
      "633000\n",
      "634000\n",
      "635000\n",
      "636000\n",
      "637000\n",
      "638000\n",
      "639000\n",
      "640000\n",
      "641000\n",
      "642000\n",
      "643000\n",
      "644000\n",
      "645000\n",
      "646000\n",
      "647000\n",
      "648000\n",
      "649000\n",
      "650000\n",
      "651000\n",
      "652000\n",
      "653000\n",
      "654000\n",
      "655000\n",
      "656000\n",
      "657000\n",
      "658000\n",
      "659000\n",
      "660000\n",
      "661000\n",
      "662000\n",
      "663000\n",
      "664000\n",
      "665000\n",
      "666000\n",
      "667000\n",
      "668000\n",
      "669000\n",
      "670000\n",
      "671000\n",
      "672000\n",
      "673000\n",
      "674000\n",
      "675000\n",
      "676000\n",
      "677000\n",
      "678000\n",
      "679000\n",
      "680000\n",
      "681000\n",
      "682000\n",
      "683000\n",
      "684000\n",
      "685000\n",
      "686000\n",
      "687000\n",
      "688000\n",
      "689000\n",
      "690000\n",
      "691000\n",
      "692000\n",
      "693000\n",
      "694000\n",
      "695000\n",
      "696000\n",
      "697000\n",
      "698000\n",
      "699000\n"
     ]
    }
   ],
   "source": [
    "tailleDB = 699438\n",
    "picTot = 0\n",
    "\n",
    "DB = np.zeros([tailleDB, 16, 16, 4])\n",
    "classY = np.zeros(tailleDB, dtype=int)\n",
    "\n",
    "countlbl = np.zeros([23,2])\n",
    "for i in range(22):\n",
    "    countlbl[i+1][0] = countlbl[i][0] + 1\n",
    "\n",
    "batchLen = 1000\n",
    "\n",
    "while picTot < tailleDB:\n",
    "    ra = np.random.randint(0,18698240)\n",
    "    dataBatch = f['S2'][ra:ra+batchLen]\n",
    "    classBatch = f['TOP_LANDCOVER'][ra:ra+batchLen]\n",
    "    pic = 0\n",
    "    while pic < batchLen:\n",
    "        if (countlbl[int(classBatch[pic]),1] < lblComplete[int(classBatch[pic]),1]) and (picTot < tailleDB):\n",
    "            DB[picTot] = dataBatch[pic]\n",
    "            classY[picTot] = classBatch[pic]\n",
    "            picTot +=1\n",
    "            countlbl[int(classBatch[pic]),1] +=1\n",
    "            if picTot%1000==0:\n",
    "                print(picTot)\n",
    "        pic += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.fft as ft\n",
    "i=0\n",
    "DB[i][:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3400\n",
      "6800\n",
      "10200\n",
      "13600\n",
      "17000\n",
      "20400\n",
      "23800\n",
      "27200\n",
      "30600\n",
      "34000\n",
      "37400\n",
      "40800\n",
      "44200\n",
      "47600\n",
      "51000\n",
      "54400\n",
      "57800\n",
      "61200\n",
      "64600\n",
      "68000\n",
      "71400\n",
      "74800\n",
      "78200\n",
      "81600\n",
      "85000\n",
      "88400\n",
      "91800\n",
      "95200\n",
      "98600\n",
      "102000\n",
      "105400\n",
      "108800\n",
      "112200\n",
      "115600\n",
      "119000\n",
      "122400\n",
      "125800\n",
      "129200\n",
      "132600\n",
      "136000\n",
      "139400\n",
      "142800\n",
      "146200\n",
      "149600\n",
      "153000\n",
      "156400\n",
      "159800\n",
      "163200\n",
      "166600\n",
      "170000\n",
      "173400\n",
      "176800\n",
      "180200\n",
      "183600\n",
      "187000\n",
      "190400\n",
      "193800\n",
      "197200\n",
      "200600\n",
      "204000\n",
      "207400\n",
      "210800\n",
      "214200\n",
      "217600\n",
      "221000\n",
      "224400\n",
      "227800\n",
      "231200\n",
      "234600\n",
      "238000\n",
      "241400\n",
      "244800\n",
      "248200\n",
      "251600\n",
      "255000\n",
      "258400\n",
      "261800\n",
      "265200\n",
      "268600\n",
      "272000\n",
      "275400\n",
      "278800\n",
      "282200\n",
      "285600\n",
      "289000\n",
      "292400\n",
      "295800\n",
      "299200\n",
      "302600\n",
      "306000\n",
      "309400\n",
      "312800\n",
      "316200\n",
      "319600\n",
      "323000\n",
      "326400\n",
      "329800\n",
      "333200\n",
      "336600\n",
      "340000\n",
      "343400\n",
      "346800\n",
      "350200\n",
      "353600\n",
      "357000\n",
      "360400\n",
      "363800\n",
      "367200\n",
      "370600\n",
      "374000\n",
      "377400\n",
      "380800\n",
      "384200\n",
      "387600\n",
      "391000\n",
      "394400\n",
      "397800\n",
      "401200\n",
      "404600\n",
      "408000\n",
      "411400\n",
      "414800\n",
      "418200\n",
      "421600\n",
      "425000\n",
      "428400\n",
      "431800\n",
      "435200\n",
      "438600\n",
      "442000\n",
      "445400\n",
      "448800\n",
      "452200\n",
      "455600\n",
      "459000\n",
      "462400\n",
      "465800\n",
      "469200\n",
      "472600\n",
      "476000\n",
      "479400\n",
      "482800\n",
      "486200\n",
      "489600\n",
      "493000\n",
      "496400\n",
      "499800\n",
      "503200\n",
      "506600\n",
      "510000\n",
      "513400\n",
      "516800\n",
      "520200\n",
      "523600\n",
      "527000\n",
      "530400\n",
      "533800\n",
      "537200\n",
      "540600\n",
      "544000\n",
      "547400\n",
      "550800\n",
      "554200\n",
      "557600\n",
      "561000\n",
      "564400\n",
      "567800\n",
      "571200\n",
      "574600\n",
      "578000\n",
      "581400\n",
      "584800\n",
      "588200\n",
      "591600\n",
      "595000\n",
      "598400\n",
      "601800\n",
      "605200\n",
      "608600\n",
      "612000\n",
      "615400\n",
      "618800\n",
      "622200\n",
      "625600\n",
      "629000\n",
      "632400\n",
      "635800\n",
      "639200\n",
      "642600\n",
      "646000\n",
      "649400\n",
      "652800\n",
      "656200\n",
      "659600\n",
      "663000\n",
      "666400\n",
      "669800\n",
      "673200\n",
      "676600\n",
      "680000\n",
      "683400\n",
      "686800\n",
      "690200\n",
      "693600\n",
      "697000\n"
     ]
    }
   ],
   "source": [
    "fourrier = np.zeros((tailleDB,16,16,4))\n",
    "for i in range(tailleDB):\n",
    "    if i%3400==0:\n",
    "        print(i)\n",
    "    for canal in range((4)):\n",
    "        fourrier[i][:,:,canal]=np.absolute(ft.fft2(DB[i][:,:,canal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourrier[12].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(16,16,4)\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "model2.add(Conv2D(32, (5, 5), input_shape=input_shape))\n",
    "\n",
    "model2.add(Conv2D(32, (5, 5)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Conv2D(32, (4, 4)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.01))\n",
    "model2.add(Dense(23))\n",
    "model2.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model2.compile(optimizer=optim,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(h5_path, batch_size, coucou):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    while True : \n",
    "        idxs = coucou\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = fourrier[batch_idxs, :,:,:]\n",
    "            Y = classY[batch_idxs]\n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_idxs = shuffle_idx(range(tailleDB))\n",
    "train_idxs, val_idxs = split_train_val(shuffled_idxs, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen = generator(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559550"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  19/1000 [..............................] - ETA: 9s - loss: 1.3780 - acc: 0.5280 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=10, validation_steps=100, validation_data=<generator..., steps_per_epoch=1000, verbose=1)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.4136 - acc: 0.4994 - val_loss: 1.3479 - val_acc: 0.5212\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.4042 - acc: 0.5028 - val_loss: 1.4118 - val_acc: 0.5128\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.3820 - acc: 0.5105 - val_loss: 1.3264 - val_acc: 0.5419\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.3859 - acc: 0.5082 - val_loss: 1.3280 - val_acc: 0.5241\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.3593 - acc: 0.5166 - val_loss: 1.3126 - val_acc: 0.5347\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.3486 - acc: 0.5213 - val_loss: 1.3595 - val_acc: 0.5228\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.3334 - acc: 0.5246 - val_loss: 1.3444 - val_acc: 0.5184\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.3456 - acc: 0.5201 - val_loss: 1.2782 - val_acc: 0.5434\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.3242 - acc: 0.5284 - val_loss: 1.2694 - val_acc: 0.5531\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.3228 - acc: 0.5288 - val_loss: 1.2946 - val_acc: 0.5406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee2409bf28>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(train_gen,steps_per_epoch=1000, epochs=10, verbose=1, validation_data=val_gen, nb_val_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'data/pred_eighties_from_full_1_without_gt.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 17825792, sblock->base_addr = 0, stored_eoa = 992887272)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDONLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 17825792, sblock->base_addr = 0, stored_eoa = 992887272)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-ef3474538c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/pred_eighties_from_full_1_without_gt.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDONLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid mode; must be one of r, r+, w, w-, x, a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'data/pred_eighties_from_full_1_without_gt.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)"
     ]
    }
   ],
   "source": [
    "test = h5.File('data/pred_eighties_from_full_1_without_gt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MappingHDF5.keys of <HDF5 file \"pred_eighties_from_full_1_without_gt.h5\" (mode r+)>>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_test_db = len(f2['S2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourrier_test = np.zeros((tailleDB,16,16,4))\n",
    "for i in range(tailleDB):\n",
    "    if i%3400==0:\n",
    "        print(i)\n",
    "    for canal in range((4)):\n",
    "        fourrier[i][:,:,canal]=np.absolute(ft.fft2(DB[i][:,:,canal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File('Db_proportions.h5', 'w')\n",
    "h5f.create_dataset('dataset_prop', data=DB)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verif = h5py.File('Db_proportions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in verif.items():\n",
    "    print(element[0])\n",
    "    print(element[1])\n",
    "    print(element[1].name)\n",
    "verif.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_elmts = [key for key in verif['/'].keys()]\n",
    "for key in list_elmts:\n",
    "    print(key)\n",
    "    print(type(verif['/'][key]))\n",
    "    print(verif['/'][key])\n",
    "    print([key for key in verif['/'][key].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxs_test = get_idxs(PATH_PREDICT_WITHOUT_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_batch_count, val_batch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1\n",
    "input_shape = (16,16,4)\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "model.add(Conv2D(8,(5,5),activation='relu',input_shape =(16,16,4)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(8,(5,5),activation='relu',input_shape =(16,16,4)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200,activation ='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "\n",
    "model.add(Dense(23,activation ='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "input_shape=(16,16,4)\n",
    "model2 = Sequential()\n",
    "model2.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "model2.add(Conv2D(32, (5, 5), input_shape=input_shape))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Conv2D(32, (5, 5)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Conv2D(32, (4, 4)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.01))\n",
    "model2.add(Dense(23))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = keras.optimizers.Adam(lr=0.001)\n",
    "optim = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model2.compile(optimizer=optim,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit_generator(train_gen, steps_per_epoch=100, epochs=4, verbose=1, validation_data=val_gen, nb_val_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for i, (name, values) in enumerate(history.history.items()):\n",
    "    plt.subplot(1, len(history.history.items()), i+1)\n",
    "    plt.plot(values)\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction routines\n",
    "\n",
    "In order to submit a result here are some gits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def prediction_generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = f['S2'][batch_idxs, :,:,:]\n",
    "        yield np.array(X)\n",
    "\n",
    "def build_h5_pred_file(pred, h5_output_path):\n",
    "    if os.path.exists(h5_output_path):\n",
    "        os.remove(h5_output_path)\n",
    "    f = h5.File(h5_output_path, 'w')\n",
    "    top_landcover_submit = f.create_dataset(\"TOP_LANDCOVER\", (len(pred), 1), maxshape=(None, 1))\n",
    "    top_landcover_submit[:, 0] = pred\n",
    "    f.close()\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction = model2.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(prediction)\n",
    "#build_h5_pred_file(np.argmax(prediction, axis = 1), PATH_SUBMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultat_avec_csv(modele,name,path):\n",
    "\n",
    "    pred_idx = get_idxs(path)\n",
    "    pred_gen = prediction_generator(path, BATCH_SIZE, pred_idx)\n",
    "    prediction = modele.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "    class_prediction = np.argmax(prediction, axis = 1)\n",
    "    tosubmit = pd.DataFrame([pred_idx,class_prediction]).transpose()\n",
    "    tosubmit.columns=[\"ID\",\"TOP_LANDCOVER\"]\n",
    "    to_submit_csv = tosubmit.to_csv('%s.csv'%(name),sep=',',index= False)\n",
    "    return prediction\n",
    "\n",
    "def resultat(modele,path):\n",
    "\n",
    "    pred_idx = get_idxs(path)\n",
    "    pred_gen = prediction_generator(path, BATCH_SIZE, pred_idx)\n",
    "    prediction = modele.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai =resultat(model2,PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_avec_csv(model2,\"jubois_palmi\",PATH_PREDICT_WITHOUT_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7700/32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    print(batch_count)\n",
    "    for b in range(batch_count):\n",
    "        if (b+1)*batch_size<\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        print(max(batch_idxs))\n",
    "        Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "        yield keras.utils.np_utils.to_categorical(np.array(Y), 23)\n",
    "\n",
    "gt_gen = gt_generator(PATH_DATA, BATCH_SIZE, pred_idx)\n",
    "gt = []\n",
    "for elem in gt_gen:\n",
    "    gt.append(elem)\n",
    "gt = np.vstack(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' #if normalize else '.i'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\",fontsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_confusion_matrix(confusion_matrix, classes):\n",
    "    real_classes = []\n",
    "    for c in range(len(classes)):\n",
    "        if np.sum(confusion_matrix[:,c])+np.sum(confusion_matrix[c, :]) != 0:\n",
    "            real_classes.append(c)\n",
    "    real_confusion_matrix = np.empty((len(real_classes), len(real_classes)))  \n",
    "    for c_index in range(len(real_classes)):\n",
    "        real_confusion_matrix[c_index,:] = confusion_matrix[real_classes[c_index], real_classes]\n",
    "    return real_confusion_matrix, real_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_top=list(f['TOP_LANDCOVER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = np.array(list_top)\n",
    "y_pred = np.argmax(essai, axis = 1)\n",
    "\n",
    "real_cnf_matrix, real_classes = clean_confusion_matrix(confusion_matrix(y_true, y_pred, labels= range(23)), range(23))\n",
    "plot_confusion_matrix(real_cnf_matrix, classes = real_classes, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_top[:20][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
